{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage supervisé : régression logistique, validation croisée et reconnaissance de visages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "1. [Régression logistique](#part1)\n",
    "    - [Sur et sous-apprentissage](#part1sec1)\n",
    "    - [Validation croisée](#part1sec2)\n",
    "    - [Application à la reconnaissance de visages](#part1sec3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "def covariance(sigma1=1., sigma2=1., theta=0.):\n",
    "    \"\"\"\n",
    "        Covariance matrix with eigenvalues sigma1 and sigma2, rotated by the angle theta.\n",
    "    \"\"\"\n",
    "    rotation = np.array([[np.cos(theta), -np.sin(theta)],\n",
    "                        [np.sin(theta), np.cos(theta)]])\n",
    "    cov = np.array([[sigma1, 0.],\n",
    "                   [0, sigma2]])\n",
    "    return rotation.dot(cov.dot(rotation.T))\n",
    "\n",
    "def gaussian_sample(mu=[0, 0], sigma1=1., sigma2=1., theta=0., n=50):\n",
    "    cov = covariance(sigma1, sigma2, theta)\n",
    "    x = multivariate_normal.rvs(mean=mu, cov=cov, size=n)\n",
    "    return x\n",
    "\n",
    "def plot_frontiere(clfs, data=None, data_labels=None, label=None, num=500, figure=True):\n",
    "    \"\"\"\n",
    "        Plot the frontiere fun(x)=0 of the classifier clf within the same range as the one\n",
    "        of the data.\n",
    "        Input:\n",
    "            clfs: classifier or list of classifiers\n",
    "            data: input data (X)\n",
    "            data_labels: data labels (y)\n",
    "            label: classifier labels as a list\n",
    "            num: discretization parameter\n",
    "            figure: create a new figure\n",
    "    \"\"\"\n",
    "    if not hasattr(clfs, '__iter__'):\n",
    "        clfs = [clfs]\n",
    "    if label is not None and not hasattr(label, '__iter__'):\n",
    "        label = [label]\n",
    "    for i in range(len(clfs)):\n",
    "        if not hasattr(clfs[i], 'decision_function'):\n",
    "            temp = lambda x: None\n",
    "            temp.decision_function = clfs[i]\n",
    "            clfs[i] = temp\n",
    "        \n",
    "    xmin, ymin = data.min(axis=0)\n",
    "    xmax, ymax = data.max(axis=0)\n",
    "    x, y = np.meshgrid(np.linspace(xmin, xmax, num), np.linspace(ymin, ymax))\n",
    "    \n",
    "    if figure:\n",
    "        plt.figure(figsize=(7, 7))\n",
    "#     plt.scatter(*data.T, c=data_labels, cmap='plasma')\n",
    "    for icl, cl in enumerate(np.unique(data_labels)):\n",
    "        plt.scatter(*data[data_labels==cl].T, label=f'Class {cl}')\n",
    "        \n",
    "    for i, clf in enumerate(clfs):\n",
    "        z = clf.decision_function(np.c_[x.ravel(), y.ravel()]).reshape(x.shape)\n",
    "        cs = plt.contour(x, y, z, [0], colors='r')\n",
    "        if label is not None:\n",
    "            cs.levels = [label[i]]\n",
    "            plt.gca().clabel(cs)\n",
    "    if figure:\n",
    "        plt.axis('image')\n",
    "    minx, miny = data[:, 0].min(), data[:, 1].min()\n",
    "    diffx, diffy = data[:, 0].max() - minx, data[:, 1].max() - miny\n",
    "    plt.axis([minx - 0.1*diffx, minx + 1.1*diffx, miny - 0.1*diffy, miny + 1.1*diffy])\n",
    "    plt.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression logistique <a id=\"part1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "X1 = gaussian_sample(mu=[0, 0])  # First class\n",
    "X2 = gaussian_sample(mu=[5, 3], n=25)  # Second class\n",
    "X3 = gaussian_sample(mu=[8, 9], n=25)  # Second class\n",
    "\n",
    "X = np.r_[X1, X2, X3]\n",
    "Y = np.r_[np.ones(X1.shape[0]), -np.ones(X2.shape[0]), -np.ones(X3.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Comparer les frontières obtenues par analyse linéaire discriminante et régression logistique pour des classes non-gaussiennes.  \n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Linear discriminant analysis\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "# Fit the model\n",
    "# Todo\n",
    "\n",
    "# End todo\n",
    "\n",
    "# Logistic regression with big penalty parameter => unregularized\n",
    "lr = LogisticRegression(C=1e8)\n",
    "# Fit the model\n",
    "# Todo\n",
    "\n",
    "# End todo\n",
    "\n",
    "plot_frontiere([lda, lr], X, Y, label=[\"LDA\", \"Logistic regression\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "X1 = gaussian_sample(mu=[0, 0])\n",
    "X2 = gaussian_sample(mu=[5, 3], n=49)\n",
    "X3 = gaussian_sample(mu=[20, 20], n=1).reshape(1, -1)\n",
    "\n",
    "X = np.r_[X1, X2, X3]\n",
    "Y = np.r_[np.ones(X1.shape[0]), -np.ones(X2.shape[0]), -np.ones(X3.shape[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "Faire de même dans cette situation (présence d'un point levier).    \n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sur et sous-apprentissage <a id=\"part1sec1\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frontiere(x):\n",
    "    w = np.array([1, 1])\n",
    "    w = w / np.linalg.norm(w)\n",
    "    w_orth = np.array([-w[1], w[0]])\n",
    "    return 5*(x@w_orth - 0.5*np.sin(2*np.pi * x@w))\n",
    "    \n",
    "n = 200\n",
    "X = np.random.rand(n, 2)\n",
    "p = 1 / (1 + np.exp(-frontiere(X)))\n",
    "y = 2*np.random.binomial(1, p) - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Commençons par afficher les données et la frontière qui les a générées.\n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plot_frontiere(frontiere, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    Afficher la frontière obtenue par régression logistique.\n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Build and fit the model\n",
    "# Todo\n",
    "\n",
    "# End todo\n",
    "\n",
    "plot_frontiere(lr.decision_function, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Faire de même avec une transformation polynomiale des données (on pourra utiliser `PolynomialFeatures`).\n",
    "Mettre en évidence le sur-apprentissage.\n",
    "\n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "for degree in [2, 3, 5, 20]:\n",
    "    poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "    lr.fit(poly.fit_transform(X), y)\n",
    "    plot_frontiere(lambda x: lr.decision_function(poly.transform(x)), X, y)\n",
    "    plt.title(f'Degree {degree}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation croisée <a id=\"part1sec2\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    \n",
    "Sélectionner par validation croisée (on utilisera `GridSearchCV`) le degré et la présence (ou non) d'intéractions dans la redescription polynomiale.\n",
    "\n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "poly_lr = Pipeline([('poly', PolynomialFeatures(include_bias=False)), ('lr', LogisticRegression(C=1e2))])\n",
    "# poly_lr.get_params()\n",
    "\n",
    "poly_lr_cv = GridSearchCV(poly_lr, dict(poly__degree=[1, 2, 3], poly__interaction_only=[False, True]),\n",
    "                          cv=3, n_jobs=-1, verbose=True)\n",
    "# Run the grid search\n",
    "# Todo\n",
    "\n",
    "# End todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Results\n",
    "print(\"Best parameters:\", poly_lr_cv.best_params_)\n",
    "\n",
    "print('\\nMean test score for each pair of parameters:')\n",
    "for pair, score in zip(poly_lr_cv.cv_results_['params'], poly_lr_cv.cv_results_['mean_test_score']):\n",
    "    print(pair, ':', score)\n",
    "# poly_lr_cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application à la reconnaissance de visages <a id=\"part1sec3\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_lfw_people\n",
    "\n",
    "lfw_people = fetch_lfw_people(data_home='~/data/', resize=0.4, min_faces_per_person=70,\n",
    "                             color=True, funneled=False, slice_=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_people.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_people.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n, h, w, _ = lfw_people.images.shape\n",
    "print(f\"Images: {n}\\nHeight: {h}\\nWidth: {w}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = np.where(np.logical_or(lfw_people.target == list(lfw_people.target_names).index('Hugo Chavez'),\n",
    "                            lfw_people.target == list(lfw_people.target_names).index('Ariel Sharon')))[0]\n",
    "images = lfw_people.images[ind]\n",
    "X = np.mean(images, axis=3).reshape(-1, h*w)\n",
    "y = lfw_people.target[ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(i, label=None):\n",
    "    plt.imshow(images[i])\n",
    "    plt.axis('image')\n",
    "    plt.grid(False)\n",
    "    plt.title(f'{lfw_people.target_names[y[i]]}' +\n",
    "              (f'\\n (pred: {lfw_people.target_names[label]})' if label is not None else ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Afficher quelques images du jeu de données.\n",
    "\n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "for i, im in enumerate(np.random.permutation(X.shape[0])[:4]):\n",
    "    plt.subplot(2, 2, i+1)\n",
    "    # Show image with show_image\n",
    "    # Todo\n",
    "\n",
    "    # End todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Séparer le jeu de données en deux ensembles et réaliser des prédictions par régression logistique.\n",
    "\n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5)\n",
    "\n",
    "# Fit the model and store the predictions in y_pred\n",
    "# Todo\n",
    "\n",
    "# End todo\n",
    "\n",
    "print(f\"Class proportions: {np.mean(y==y.min()), np.mean(y==y.max())}\")\n",
    "print(f\"Test score: {lr.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Afficher quelques images du jeu de données et leurs prédictions.\n",
    "\n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i, im in enumerate(np.random.permutation(X.shape[0])[:16]):\n",
    "    plt.subplot(4, 4, i+1)\n",
    "    # Show image and prediction with show_image\n",
    "    # Todo\n",
    "\n",
    "    # End todo\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "Afficher, sous forme d'image, les coefficients utilisés par la régression logistique.\n",
    "\n",
    "<!-- <br> -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "plt.imshow(lr.coef_.reshape(h, w), cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.axis('image')\n",
    "plt.grid(False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
